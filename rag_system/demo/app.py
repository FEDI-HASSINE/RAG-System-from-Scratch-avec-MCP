#!/usr/bin/env python3
"""
RAG System ‚Äî Interface Streamlit

Lancez avec:
    streamlit run app.py
"""

import os
import sys
import time

# Ensure rag_system is importable
DEMO_DIR = os.path.dirname(os.path.abspath(__file__))
RAG_SYSTEM_DIR = os.path.dirname(DEMO_DIR)
if RAG_SYSTEM_DIR not in sys.path:
    sys.path.insert(0, RAG_SYSTEM_DIR)

import streamlit as st
import pandas as pd

from agents.rag_agent import RAGAgent, RAGConfig, RetrievalStrategy

# ============================================================
# Configuration
# ============================================================

st.set_page_config(
    page_title="RAG System Demo",
    page_icon="üîç",
    layout="wide",
)


@st.cache_resource
def get_agent():
    """Charge l'agent RAG (cache pour performance)."""
    config = RAGConfig(
        mcp_base_url="http://localhost:8000",
        retrieval_strategy=RetrievalStrategy.RERANK,
        initial_top_k=10,
        final_top_k=5,
        include_trace=True,
    )
    return RAGAgent(config)


# ============================================================
# Sidebar
# ============================================================

with st.sidebar:
    st.image("https://img.icons8.com/color/96/search--v1.png", width=64)
    st.title("RAG System")
    st.markdown("---")

    # Health check
    agent = get_agent()
    health = agent.health_check()

    st.subheader("ü©∫ √âtat du syst√®me")
    col1, col2 = st.columns(2)
    with col1:
        if health.get("mcp_server"):
            st.success("MCP ‚úÖ")
        else:
            st.error("MCP ‚ùå")
    with col2:
        if health.get("llm_service"):
            st.success("LLM ‚úÖ")
        else:
            st.warning("LLM ‚ö†Ô∏è")

    st.markdown("---")

    # Options
    st.subheader("‚öôÔ∏è Options")
    top_k = st.slider("Chunks √† afficher", 1, 10, 5)
    show_trace = st.checkbox("Voir raisonnement RAG", value=True)

    st.markdown("---")
    st.caption("Phase 8 ‚Äî D√©mo RAG System")


# ============================================================
# Main Content
# ============================================================

st.title("üîç RAG System Demo")
st.markdown(
    """
    Posez une question et observez comment le syst√®me RAG r√©cup√®re et exploite vos documents.
    """
)

# Input
question = st.text_input(
    "üí¨ Votre question",
    placeholder="Ex: What is Agent2Agent protocol?",
    key="question_input",
)

col_btn, col_clear = st.columns([1, 5])
with col_btn:
    run_btn = st.button("‚ñ∂Ô∏è Run RAG", type="primary", use_container_width=True)
with col_clear:
    if st.button("üóëÔ∏è Clear"):
        st.session_state.pop("last_response", None)
        st.rerun()

# ============================================================
# RAG Execution
# ============================================================

if run_btn and question.strip():
    if not health.get("mcp_server"):
        st.error("‚ùå MCP Server indisponible. D√©marrez-le avec:")
        st.code("cd rag_system/mcp_server && uvicorn main:app --reload", language="bash")
    else:
        with st.spinner("üß† RAG en cours..."):
            start = time.time()
            response = agent.answer(question.strip(), include_trace=show_trace)
            elapsed = (time.time() - start) * 1000

        st.session_state["last_response"] = response
        st.session_state["last_question"] = question.strip()
        st.session_state["last_elapsed"] = elapsed
        st.session_state["last_top_k"] = top_k


# ============================================================
# Display Results
# ============================================================

if "last_response" in st.session_state:
    response = st.session_state["last_response"]
    question_used = st.session_state.get("last_question", "")
    elapsed = st.session_state.get("last_elapsed", 0)
    top_k_used = st.session_state.get("last_top_k", 5)

    st.markdown("---")

    # Chunks r√©cup√©r√©s
    with st.expander("üîç Chunks r√©cup√©r√©s", expanded=True):
        chunks = agent.retrieve_and_rerank(question_used, initial_k=10, final_k=top_k_used)
        if chunks:
            data = []
            for i, chunk in enumerate(chunks, 1):
                score = chunk.get("rerank_score") or chunk.get("score", 0)
                source = chunk.get("source", "?")
                text = (chunk.get("text") or chunk.get("content", ""))[:200]
                data.append({"#": i, "Score": f"{score:.2f}", "Source": source, "Extrait": text})
            df = pd.DataFrame(data)
            st.dataframe(df, use_container_width=True, hide_index=True)
        else:
            st.info("Aucun chunk trouv√©.")

    # R√©ponse finale
    st.subheader("üß† R√©ponse")
    st.markdown(response.answer)

    # Sources
    if response.sources:
        st.caption(f"üìö Sources: {', '.join(response.sources)}")

    # Trace du pipeline
    if show_trace and response.trace:
        with st.expander("üìä Raisonnement RAG (Pipeline Trace)", expanded=False):
            st.markdown(
                """
                **√âtapes du pipeline RAG :**
                1. **Embedding query** ‚Äî Vectorisation de la question
                2. **Retrieving top chunks** ‚Äî Recherche dans FAISS
                3. **Reranking** ‚Äî R√©ordonnancement par Cross-Encoder
                4. **Prompt injection** ‚Äî Construction du prompt avec contexte
                5. **LLM generation** ‚Äî G√©n√©ration de la r√©ponse
                """
            )
            st.markdown("---")
            trace_data = []
            for step in response.trace.steps:
                status = "‚úÖ" if step.success else "‚ùå"
                trace_data.append({
                    "√âtape": f"{status} {step.name}",
                    "Dur√©e (ms)": f"{step.duration_ms:.1f}",
                    "D√©tails": step.output_summary,
                })
            st.table(pd.DataFrame(trace_data))
            st.metric("‚è±Ô∏è Temps total", f"{response.trace.total_duration_ms:.0f} ms")

    # Export
    st.markdown("---")
    md_export = f"""# RAG Response

## Question
{question_used}

## Answer
{response.answer}

## Sources
{', '.join(response.sources) if response.sources else 'Aucune'}

## Trace
"""
    if response.trace:
        for step in response.trace.steps:
            status = "‚úÖ" if step.success else "‚ùå"
            md_export += f"- {status} **{step.name}**: {step.duration_ms:.1f}ms ‚Äî {step.output_summary}\n"
        md_export += f"\n**Total:** {response.trace.total_duration_ms:.1f}ms\n"

    st.download_button(
        label="üì• Export Markdown",
        data=md_export,
        file_name="rag_response.md",
        mime="text/markdown",
    )

# ============================================================
# Footer
# ============================================================

st.markdown("---")
st.caption("RAG System from Scratch avec MCP ‚Äî Phase 8 Demo")
