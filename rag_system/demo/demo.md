# RAG System Demo ‚Äî Phase 8

Cette phase propose deux interfaces pour interagir avec le RAG System :

| Mode | Fichier | Usage |
|------|---------|-------|
| CLI (Typer) | `rag_cli.py` | Dev / Jury technique |
| UI (Streamlit) | `app.py` | D√©monstration visuelle |

---

## Pr√©-requis

1. **MCP Server** en cours d'ex√©cution :
   ```bash
   cd rag_system/mcp_server
   uvicorn main:app --reload
   ```

2. **D√©pendances Python** (d√©j√† install√©es par l'agent) :
   ```bash
   pip install typer rich streamlit pandas matplotlib
   ```

3. *(Optionnel)* Cl√© OpenAI pour un LLM r√©el :
   ```bash
   export OPENAI_API_KEY=sk-...
   ```

---

## Mode CLI

### Poser une question
```bash
cd rag_system/demo
python rag_cli.py ask "What is A2A protocol?"
```

### Options
| Flag | Description |
|------|-------------|
| `--top-k` / `-k` | Nombre de chunks affich√©s (d√©faut : 5) |
| `--trace / --no-trace` | Afficher la trace du pipeline |
| `--mcp URL` | URL du serveur MCP |

### Autres commandes
```bash
python rag_cli.py health      # √âtat du syst√®me
python rag_cli.py stats       # Statistiques agent
python rag_cli.py export "Ma question" -o reponse.md
```

### Exemple de sortie
```
‚ùì Question: What is A2A protocol?

üîç Retrieved Chunks:
‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ # ‚îÉ Score  ‚îÉ Source        ‚îÉ Extrait                                           ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ 1 ‚îÇ 0.92   ‚îÇ a2a_spec.md   ‚îÇ A2A allows agents to publish Agent Cards...       ‚îÇ
‚îÇ 2 ‚îÇ 0.87   ‚îÇ protocols.md  ‚îÇ Agent interoperability enables...                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üß† Final Answer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ A2A is an open protocol enabling agents to discover and         ‚îÇ
‚îÇ collaborate using Agent Cards.                                   ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

üìö Sources: a2a_spec.md, protocols.md

üìä Pipeline Trace:
   ‚úÖ retrieve: 3.5ms ‚Äî found 10 chunks
   ‚úÖ rerank: 120ms ‚Äî top 5 after rerank
   ‚úÖ build_context: 0.2ms ‚Äî context=1024 chars
   ‚úÖ llm_generate: 450ms ‚Äî response=156 chars
   ‚è±Ô∏è  Total: 574ms
```

---

## Mode UI (Streamlit)

### Lancer l'interface
```bash
cd rag_system/demo
streamlit run app.py
```

Ouvrez ensuite `http://localhost:8501` dans votre navigateur.

### Fonctionnalit√©s

| Zone UI | Fonction |
|---------|----------|
| **Input** | Question utilisateur |
| **Bouton** | ‚ñ∂Ô∏è Run RAG |
| **Expandable panel** | Chunks r√©cup√©r√©s avec scores |
| **Toggle** | Voir raisonnement RAG (pipeline trace) |
| **Download** | Export r√©ponse Markdown |

### Capture d'√©cran (√† ajouter)
Placez vos captures dans `rag_system/demo/screenshots/`.

---

## Bouton "Voir raisonnement RAG"

Affiche les √©tapes du pipeline :

1. **Embedding query** ‚Äî Vectorisation de la question
2. **Retrieving top chunks** ‚Äî Recherche dans FAISS
3. **Reranking** ‚Äî R√©ordonnancement par Cross-Encoder
4. **Prompt injection** ‚Äî Construction du prompt avec contexte
5. **LLM generation** ‚Äî G√©n√©ration de la r√©ponse

> ‚ö†Ô∏è Pas de chain-of-thought r√©el ‚Äî seulement la logique du pipeline.

---

## S√©curit√©

- Les cl√©s API (ex. `OPENAI_API_KEY`) sont charg√©es via **variables d'environnement** et ne sont jamais affich√©es.
- Le serveur MCP est en local (`localhost:8000`) par d√©faut.

---

## Fichiers

| Fichier | Description |
|---------|-------------|
| `rag_cli.py` | CLI Typer avec commandes ask, health, stats, export |
| `app.py` | Interface Streamlit |
| `demo.md` | Ce document |
| `screenshots/` | Captures d'√©cran pour portfolio |

---

## Troubleshooting

| Probl√®me | Solution |
|----------|----------|
| MCP Server ‚ùå | `cd rag_system/mcp_server && uvicorn main:app --reload` |
| LLM ‚ö†Ô∏è (mock) | D√©finir `OPENAI_API_KEY` ou utiliser Ollama |
| Aucun chunk | V√©rifier que `vector_store/index.faiss` existe |

---

*Phase 8 ‚Äî RAG System from Scratch avec MCP*
