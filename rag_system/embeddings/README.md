# ğŸ§  Embeddings â€” Vectorisation (Phase 2)

## ğŸ¯ Objectif

Convertir les chunks textuels en vecteurs numÃ©riques pour la recherche sÃ©mantique.

## ğŸ”§ ProblÃ¨mes rÃ©solus

| ProblÃ¨me | Solution |
|----------|----------|
| Choix du modÃ¨le d'embedding | `embedding_models.py` â€” Support multi-modÃ¨les (SentenceTransformers, OpenAI) |
| Vectorisation batch inefficace | Traitement par lots optimisÃ© |
| Stockage des embeddings | IntÃ©gration avec FAISS via `indexing_pipeline.py` |
| CohÃ©rence modÃ¨le/index | MÃ©tadonnÃ©es sauvegardÃ©es avec le modÃ¨le utilisÃ© |

## ğŸ“ Fichiers

```
embeddings/
â”œâ”€â”€ embedding_models.py    # Service d'embedding unifiÃ©
â””â”€â”€ indexing_pipeline.py   # Pipeline de crÃ©ation d'index
```

## ğŸš€ Utilisation

### GÃ©nÃ©rer un embedding
```python
from embeddings.embedding_models import get_embedding_service

service = get_embedding_service("sentence-transformers")
vector = service.embed("Texte Ã  vectoriser")
print(f"Dimension: {len(vector)}")  # 384 pour all-MiniLM-L6-v2
```

### CrÃ©er l'index complet
```python
from embeddings.indexing_pipeline import IndexingPipeline

pipeline = IndexingPipeline()
result = pipeline.run()
print(f"Vecteurs indexÃ©s: {result.total_vectors}")
```

Ou en ligne de commande :
```bash
cd rag_system
python run_indexing.py
```

## ğŸ¤– ModÃ¨les supportÃ©s

| ModÃ¨le | Type | Dimensions | Vitesse |
|--------|------|------------|---------|
| `all-MiniLM-L6-v2` | SentenceTransformers | 384 | âš¡ Rapide |
| `all-mpnet-base-v2` | SentenceTransformers | 768 | ğŸ¯ PrÃ©cis |
| `text-embedding-ada-002` | OpenAI | 1536 | â˜ï¸ API |

## âš™ï¸ Configuration

```python
from embeddings.embedding_models import EmbeddingService

service = EmbeddingService(
    model_type="sentence-transformers",
    model_name="all-MiniLM-L6-v2"
)
```

Variable d'environnement pour OpenAI :
```bash
export OPENAI_API_KEY=sk-...
```
